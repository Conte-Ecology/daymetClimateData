# Daymet Download & Processing

## This script completes the following:

1. Download Daymet climate data (NetCDF-4 format) mosaics across North America
2. Spatially averages the climate records for NHDplus Version 2 Catchments. Any point which falls within the outline of the catchment is included in the average. If no point falls inside the catchment, the point nearest to the catchment centroid is used.
3. Writes the data into an SQLite database

---
##Load Libraries
```{r Libraries}
rm(list=setdiff(ls(), "CATCHMENTS"))

library(maptools)
library(dplyr) 
library(RSQLite)
library(RSQLite.extfuns)
library(ncdf4)
library(reshape2)
library(tcltk)
```

---
## Enter Inputs
```{r Inputs}

# Define the projections of the shapefiles and Daymet data
#   Note: The Daymet proj4 is just the coordinate system the projection is based on.
#PROJ4.NHD     <- "+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs +towgs84=0,0,0"
PROJ4.DAYMET  <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"

# Temporal range
START_YEAR <- 1980
END_YEAR <- 2013

# Variables
VARIABLES <- c('tmax', 'tmin', 'prcp', 'dayl', 'srad', 'vp', 'swe')

# Destination folder of the raw Daymet data
DAYMET_DIRECTORY <- 'F:/KPONEIL/SourceData/climate/DAYMET/raw'
#DAYMET_DIRECTORY <- '//IGSAGBEBWS-MJO7/projects/dataIn/environmental/climate/daymet/Daily'

# Name of the database with Daymet data paired to NHDPlus catchments
DATABASE_NAME <- 'DaymetByHRDCatchments'

CATCHMENTS <- readShapePoly('C:/KPONEIL/daymetToHUCs/shapefiles/NortheastHRD_Catchments_DaymetPrj.shp', proj4string=CRS(PROJ4.DAYMET))

# Run this until package is created
source('C:/KPONEIL/GitHub/personal/dataProcessing/scripts/functions/daymetMosaicDownload.R')
source('C:/KPONEIL/GitHub/personal/dataProcessing/scripts/functions/spatialAverageDaymet.R')
source('C:/KPONEIL/GitHub/personal/dataProcessing/scripts/functions/tileCatchmentsShapefile.R')
source('C:/KPONEIL/GitHub/personal/dataProcessing/scripts/functions/transformShapefile.R')
source('C:/KPONEIL/GitHub/personal/dataProcessing/scripts/functions/convertDaymetToSQLiteDatabase.R')
```

---
## Download the Daymet Mosaics
```{r Download Daymet}

daymetMosaicDownload(startYear = START_YEAR,
                     endYear = END_YEAR,
                     variables = VARIABLES,
                     destinationFolder = file.path(DAYMET_DIRECTORY),
                     retryFailedDownloads = TRUE)
```

---
## Create and Connect to Database
```{r Make database connection}

setwd(DAYMET_DIRECTORY)

# If the database does not exist then create one
if ( !file.exists(DATABASE_NAME) ) {src_sqlite(DATABASE_NAME, create = T)}

# Connect to the database
database <- dbConnect(SQLite(), DATABASE_NAME)
```

---
## Average the Daymet Records by Catchment
```{r Average Daymet by catchment}

# Variables and years to average and add to database
B <- proc.time()[3]
convertDaymetToSQLiteDatabase(databaseConnection = database,
                                tableName = "climateRecord",
                                years = seq(from = START_YEAR, to = END_YEAR, by = 1),
                                variables = VARIABLES,
                                daymetDirectory = DAYMET_DIRECTORY,
                                catchmentsShapefile = CATCHMENTS,
                                daymetProj4string = PROJ4.DAYMET)
E <- proc.time()[3]

print("Total time: ", (E - B)/3600, " hours.")
```

---
## Example of returning data from SQLite Database
```{r Return record from database}

record <- returnRecordFromDaymetDB(databaseFilePath = file.path('C:/KPONEIL/workspace/DaymetByHRDCatchments2'), 
                         tableName = 'climateRecord', 
                         startDate = "1980-01-01", 
                         endDate = "1980-01-31", 
                         featureIDs = c(887528),
                         variables = c('tmax', 'tmin', 'prcp'))#, 'dayl', 'srad', 'vp', 'swe'))
```